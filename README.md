# Action-and-Emotion-Recognition-by-Graph-Convolutional-Network
Graph Deep Learning Course Presentation - Action and Emotion Recognition by Graph Convolutional Network(GCN)
Introduction
Graph Convolutional Networks (GCNs) are a powerful neural network architecture for processing data represented as graphs. They enable effective feature learning directly from the graph structure, making them ideal for tasks where data relationships can be naturally expressed as graphs. This project explores the application of GCNs to action and emotion recognition, demonstrating how these networks can interpret complex, interrelated data to recognize human actions and emotional states from motion-captured data.

Definitions
Graph Convolutional Network (GCN): A type of neural network that operates directly on graphs, allowing for the learning of node representations that incorporate neighborhood information.
Action Recognition: The process of identifying a specific action from a series of observations of a person or persons, typically using video or sensor data.
Emotion Recognition: The task of recognizing human emotions from physical states or facial expressions, often utilizing data from various sensors or visual inputs.
Research and Further Reading
For a detailed exploration of the theories and methodologies implemented in this project, please refer to our comprehensive documentation and studies on ResearchGate. (Please replace this placeholder link with your actual ResearchGate project link.)

Project Structure
The repository is structured as follows:

/data: Contains datasets used in the models.
/models: Includes the scripts for the GCN models implemented.
/notebooks: Jupyter notebooks for demonstrations and testing.
/utils: Utility scripts for data preprocessing and other auxiliary functions.
Gallery
Below are some visualizations from the project. These images demonstrate the input data, the process of graph construction, and the final emotion recognition results.

Input Data Visualization
<!-- Replace with your actual image path -->

Graph Construction
<!-- Replace with your actual image path -->

Training Process
<!-- Replace with your actual image path -->

Action Recognition Output
<!-- Replace with your actual image path -->

Emotion Recognition Output
<!-- Replace with your actual image path -->
